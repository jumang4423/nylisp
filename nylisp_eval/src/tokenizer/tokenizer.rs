pub const LPAREN: &str = "ğŸ’–";
pub const RPAREN: &str = "ğŸ’”";
pub const QUOTE: &str = "ğŸ˜ª";
pub const TRUE: &str = "ğŸ‘";
pub const FALSE: &str = "ğŸ‘";
pub const IF: &str = "ğŸ¶";
pub const VAR: &str = "ğŸŒ¹";
pub const CLOSURE: &str = "ğŸ·";
pub const SCOPED_LET: &str = "ğŸ™";


pub struct Tokenizer {
    pub input: String,
}

impl Tokenizer {
    pub fn new(input: String) -> Tokenizer {
        Tokenizer { input }
    }

    pub fn tokenize(&self) -> Vec<String> {
        let paren_spaced = self.input
            .replace(LPAREN.chars().collect::<Vec<char>>()[0], format!(" {} ", LPAREN).as_str())
            .replace(RPAREN.chars().collect::<Vec<char>>()[0], format!(" {} ", RPAREN).as_str())
            .replace(QUOTE.chars().collect::<Vec<char>>()[0], format!(" {} ", QUOTE).as_str());
        paren_spaced.split_whitespace()
            .map(|x| x.to_string())
            .collect()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn tokenize_nylisp_test1() {
        let input = "ğŸ’–+ 1 2ğŸ’”";
        let expected = vec!["ğŸ’–", "+", "1", "2", "ğŸ’”"];
        let tokenizer = Tokenizer::new(input.to_string());
        let tokens = tokenizer.tokenize();
        assert_eq!(tokens, expected);
    }

    #[test]
    fn tokenize_nylisp_test2() {
        let input = "ğŸ’–+ ğŸ’–* 2 3ğŸ’” ğŸ’–* 4 5ğŸ’”ğŸ’”";
        let expected = vec!["ğŸ’–", "+", "ğŸ’–", "*", "2", "3", "ğŸ’”", "ğŸ’–", "*", "4", "5", "ğŸ’”", "ğŸ’”"];
        let tokenizer = Tokenizer::new(input.to_string());
        let tokens = tokenizer.tokenize();
        assert_eq!(tokens, expected);
    }
}